{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "645ac728-b8dc-4306-9675-fd6122c060f3",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: llama-index-llms-openai in /usr/local/lib/python3.8/dist-packages (0.2.0)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.40.0 in /usr/local/lib/python3.8/dist-packages (from llama-index-llms-openai) (1.42.0)\n",
      "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from llama-index-llms-openai) (0.11.2)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.8/dist-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.8/dist-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai) (4.66.5)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai) (0.27.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.8/dist-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai) (4.12.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai) (0.5.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.8/dist-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai) (4.0.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.8/dist-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai) (1.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai) (2.8.2)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (1.16.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (0.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (2024.6.1)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (6.0.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (1.24.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (10.4.0)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (1.0.8)\n",
      "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (3.9.1)\n",
      "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (2.0.32)\n",
      "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (0.6.7)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (0.7.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (8.5.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (2.32.3)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (1.2.14)\n",
      "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (3.1)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (1.5.8)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (3.10.5)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->llama-index-llms-openai) (2019.11.28)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.8/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->llama-index-llms-openai) (1.0.5)\n",
      "Requirement already satisfied: idna in /usr/lib/python3/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->llama-index-llms-openai) (2.8)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2; python_version < \"3.11\" in /usr/local/lib/python3.8/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->llama-index-llms-openai) (1.1.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from pydantic<3,>=1.9.0->openai<2.0.0,>=1.40.0->llama-index-llms-openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.8/dist-packages (from pydantic<3,>=1.9.0->openai<2.0.0,>=1.40.0->llama-index-llms-openai) (2.20.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (1.0.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (8.1.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (2024.7.24)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (1.4.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17; python_version < \"3.13\" and (platform_machine == \"aarch64\" or (platform_machine == \"ppc64le\" or (platform_machine == \"x86_64\" or (platform_machine == \"amd64\" or (platform_machine == \"AMD64\" or (platform_machine == \"win32\" or platform_machine == \"WIN32\")))))) in /usr/local/lib/python3.8/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (3.0.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.8/dist-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (3.22.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (2.2.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0; python_version < \"3.11\" in /usr/local/lib/python3.8/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (4.0.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (6.0.5)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (1.3.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (2.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (23.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (1.9.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.8/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->llama-index-llms-openai) (0.14.0)\n",
      "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.8/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-openai) (23.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: llama-index-embeddings-openai in /usr/local/lib/python3.8/dist-packages (0.2.3)\n",
      "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from llama-index-embeddings-openai) (0.11.2)\n",
      "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from llama-index-embeddings-openai) (1.42.0)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.16.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (0.7.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2.32.3)\n",
      "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (3.1)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2.0.32)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.5.8)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2024.6.1)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (10.4.0)\n",
      "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.2.14)\n",
      "Requirement already satisfied: httpx in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (0.27.2)\n",
      "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (3.9.1)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (3.10.5)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (4.12.2)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.0.8)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2.8.2)\n",
      "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.24.4)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (8.5.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.8/dist-packages (from openai>=1.1.0->llama-index-embeddings-openai) (4.0.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.8/dist-packages (from openai>=1.1.0->llama-index-embeddings-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from openai>=1.1.0->llama-index-embeddings-openai) (0.5.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.8/dist-packages (from openai>=1.1.0->llama-index-embeddings-openai) (1.3.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.8/dist-packages (from tiktoken>=0.3.3->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2024.7.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2019.11.28)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (3.3.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17; python_version < \"3.13\" and (platform_machine == \"aarch64\" or (platform_machine == \"ppc64le\" or (platform_machine == \"x86_64\" or (platform_machine == \"amd64\" or (platform_machine == \"AMD64\" or (platform_machine == \"win32\" or platform_machine == \"WIN32\")))))) in /usr/local/lib/python3.8/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (3.0.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.8/dist-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (3.22.0)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.8/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.0.5)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.4.2)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (8.1.7)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.4.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0; python_version < \"3.11\" in /usr/local/lib/python3.8/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.9.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (6.0.5)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (23.1.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.3.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from pydantic<3.0.0,>=2.0.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.8/dist-packages (from pydantic<3.0.0,>=2.0.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2.20.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2; python_version < \"3.11\" in /usr/local/lib/python3.8/dist-packages (from anyio<5,>=3.5.0->openai>=1.1.0->llama-index-embeddings-openai) (1.1.3)\n",
      "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.8/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (23.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.8/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: llama-index-finetuning in /usr/local/lib/python3.8/dist-packages (0.1.7)\n",
      "Requirement already satisfied: sentence-transformers<3.0.0,>=2.3.0 in /usr/local/lib/python3.8/dist-packages (from llama-index-finetuning) (2.7.0)\n",
      "Requirement already satisfied: llama-index-llms-gradient<0.2.0,>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from llama-index-finetuning) (0.1.2)\n",
      "Requirement already satisfied: llama-index-postprocessor-cohere-rerank<0.2.0,>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from llama-index-finetuning) (0.1.7)\n",
      "Collecting llama-index-core<0.11.0,>=0.10.11.post1\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/c9/bb/524971a3f038701b8751b71f0ff825a8df82c0f511d3860cb58a8fe93045/llama_index_core-0.10.68.post1-py3-none-any.whl (1.6 MB)\n",
      "Requirement already satisfied: llama-index-embeddings-adapter<0.2.0,>=0.1.2 in /usr/local/lib/python3.8/dist-packages (from llama-index-finetuning) (0.1.3)\n",
      "Collecting llama-index-llms-openai<0.2.0,>=0.1.1\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/dd/60/54155af74479199bdbd34394af6d907be7103b8bb7990ec6ef6e54b7dd17/llama_index_llms_openai-0.1.31-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from sentence-transformers<3.0.0,>=2.3.0->llama-index-finetuning) (1.3.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from sentence-transformers<3.0.0,>=2.3.0->llama-index-finetuning) (1.10.1)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from sentence-transformers<3.0.0,>=2.3.0->llama-index-finetuning) (10.4.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.8/dist-packages (from sentence-transformers<3.0.0,>=2.3.0->llama-index-finetuning) (4.38.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from sentence-transformers<3.0.0,>=2.3.0->llama-index-finetuning) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from sentence-transformers<3.0.0,>=2.3.0->llama-index-finetuning) (2.4.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from sentence-transformers<3.0.0,>=2.3.0->llama-index-finetuning) (1.24.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.8/dist-packages (from sentence-transformers<3.0.0,>=2.3.0->llama-index-finetuning) (0.23.5)\n",
      "Requirement already satisfied: gradientai<2.0.0,>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from llama-index-llms-gradient<0.2.0,>=0.1.1->llama-index-finetuning) (1.13.1)\n",
      "Requirement already satisfied: cohere<6.0.0,>=5.1.1 in /usr/local/lib/python3.8/dist-packages (from llama-index-postprocessor-cohere-rerank<0.2.0,>=0.1.1->llama-index-finetuning) (5.8.1)\n",
      "Requirement already satisfied: pydantic<3.0 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (2.8.2)\n",
      "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (3.1)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (3.10.5)\n",
      "Requirement already satisfied: httpx in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (0.27.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (4.12.2)\n",
      "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (2.0.32)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (0.7.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (8.5.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (2.0.3)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (1.2.14)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (1.5.8)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (2.32.3)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (1.16.0)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (1.0.8)\n",
      "Requirement already satisfied: nltk!=3.9,>=3.8.1 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (3.9.1)\n",
      "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (0.6.7)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.40.0 in /usr/local/lib/python3.8/dist-packages (from llama-index-llms-openai<0.2.0,>=0.1.1->llama-index-finetuning) (1.42.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->sentence-transformers<3.0.0,>=2.3.0->llama-index-finetuning) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->sentence-transformers<3.0.0,>=2.3.0->llama-index-finetuning) (3.5.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.8/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers<3.0.0,>=2.3.0->llama-index-finetuning) (0.15.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers<3.0.0,>=2.3.0->llama-index-finetuning) (3.15.4)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers<3.0.0,>=2.3.0->llama-index-finetuning) (0.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers<3.0.0,>=2.3.0->llama-index-finetuning) (23.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers<3.0.0,>=2.3.0->llama-index-finetuning) (2024.7.24)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.3.0->llama-index-finetuning) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0; platform_system == \"Linux\" and platform_machine == \"x86_64\" and python_version < \"3.13\" in /usr/local/lib/python3.8/dist-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.3.0->llama-index-finetuning) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.3.0->llama-index-finetuning) (2.20.5)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.3.0->llama-index-finetuning) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.3.0->llama-index-finetuning) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.3.0->llama-index-finetuning) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.3.0->llama-index-finetuning) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.3.0->llama-index-finetuning) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.3.0->llama-index-finetuning) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.3.0->llama-index-finetuning) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.3.0->llama-index-finetuning) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.3.0->llama-index-finetuning) (11.0.2.54)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.8/dist-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.3.0->llama-index-finetuning) (1.13.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.3.0->llama-index-finetuning) (3.1.2)\n",
      "Requirement already satisfied: aenum>=3.1.11 in /usr/local/lib/python3.8/dist-packages (from gradientai<2.0.0,>=1.6.0->llama-index-llms-gradient<0.2.0,>=0.1.1->llama-index-finetuning) (3.1.15)\n",
      "Requirement already satisfied: urllib3>=1.25.3 in /usr/local/lib/python3.8/dist-packages (from gradientai<2.0.0,>=1.6.0->llama-index-llms-gradient<0.2.0,>=0.1.1->llama-index-finetuning) (2.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.8/dist-packages (from gradientai<2.0.0,>=1.6.0->llama-index-llms-gradient<0.2.0,>=0.1.1->llama-index-finetuning) (2.8.2)\n",
      "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.2.0,>=0.1.1->llama-index-finetuning) (2.32.0.20240712)\n",
      "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /usr/local/lib/python3.8/dist-packages (from cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.2.0,>=0.1.1->llama-index-finetuning) (2.20.1)\n",
      "Requirement already satisfied: boto3<2.0.0,>=1.34.0 in /usr/local/lib/python3.8/dist-packages (from cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.2.0,>=0.1.1->llama-index-finetuning) (1.35.8)\n",
      "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in /usr/local/lib/python3.8/dist-packages (from cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.2.0,>=0.1.1->llama-index-finetuning) (1.9.5)\n",
      "Requirement already satisfied: parameterized<0.10.0,>=0.9.0 in /usr/local/lib/python3.8/dist-packages (from cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.2.0,>=0.1.1->llama-index-finetuning) (0.9.0)\n",
      "Requirement already satisfied: httpx-sse==0.4.0 in /usr/local/lib/python3.8/dist-packages (from cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.2.0,>=0.1.1->llama-index-finetuning) (0.4.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from pydantic<3.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (0.7.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (6.0.5)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (1.4.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (23.1.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (2.4.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0; python_version < \"3.11\" in /usr/local/lib/python3.8/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (1.9.4)\n",
      "Requirement already satisfied: idna in /usr/lib/python3/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (2.8)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.8/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (1.3.0)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.8/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (1.0.5)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (2019.11.28)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.8/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (4.0.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17; python_version < \"3.13\" and (platform_machine == \"aarch64\" or (platform_machine == \"ppc64le\" or (platform_machine == \"x86_64\" or (platform_machine == \"amd64\" or (platform_machine == \"AMD64\" or (platform_machine == \"win32\" or platform_machine == \"WIN32\")))))) in /usr/local/lib/python3.8/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (3.0.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.8/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (3.3.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (1.0.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk!=3.9,>=3.8.1->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (8.1.7)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.8/dist-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (3.22.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai<0.2.0,>=0.1.1->llama-index-finetuning) (0.5.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.8/dist-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai<0.2.0,>=0.1.1->llama-index-finetuning) (1.9.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.8/dist-packages (from nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch>=1.11.0->sentence-transformers<3.0.0,>=2.3.0->llama-index-finetuning) (12.6.20)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from sympy->torch>=1.11.0->sentence-transformers<3.0.0,>=2.3.0->llama-index-finetuning) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers<3.0.0,>=2.3.0->llama-index-finetuning) (2.1.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->gradientai<2.0.0,>=1.6.0->llama-index-llms-gradient<0.2.0,>=0.1.1->llama-index-finetuning) (1.14.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.8/dist-packages (from boto3<2.0.0,>=1.34.0->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.2.0,>=0.1.1->llama-index-finetuning) (1.0.1)\n",
      "Requirement already satisfied: botocore<1.36.0,>=1.35.8 in /usr/local/lib/python3.8/dist-packages (from boto3<2.0.0,>=1.34.0->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.2.0,>=0.1.1->llama-index-finetuning) (1.35.8)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from boto3<2.0.0,>=1.34.0->cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.2.0,>=0.1.1->llama-index-finetuning) (0.10.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.8/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (0.14.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2; python_version < \"3.11\" in /usr/local/lib/python3.8/dist-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (1.1.3)\n",
      "\u001b[31mERROR: llama-parse 0.5.1 has requirement llama-index-core>=0.11.0, but you'll have llama-index-core 0.10.68.post1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: llama-index 0.11.2 has requirement llama-index-core<0.12.0,>=0.11.2, but you'll have llama-index-core 0.10.68.post1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: llama-index 0.11.2 has requirement llama-index-llms-openai<0.3.0,>=0.2.0, but you'll have llama-index-llms-openai 0.1.31 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: llama-index-readers-llama-parse 0.2.0 has requirement llama-index-core<0.12.0,>=0.11.0, but you'll have llama-index-core 0.10.68.post1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: llama-index-readers-file 0.2.0 has requirement llama-index-core<0.12.0,>=0.11.0, but you'll have llama-index-core 0.10.68.post1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: llama-index-question-gen-openai 0.2.0 has requirement llama-index-core<0.12.0,>=0.11.0, but you'll have llama-index-core 0.10.68.post1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: llama-index-question-gen-openai 0.2.0 has requirement llama-index-llms-openai<0.3.0,>=0.2.0, but you'll have llama-index-llms-openai 0.1.31 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: llama-index-program-openai 0.2.0 has requirement llama-index-core<0.12.0,>=0.11.0, but you'll have llama-index-core 0.10.68.post1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: llama-index-program-openai 0.2.0 has requirement llama-index-llms-openai<0.3.0,>=0.2.0, but you'll have llama-index-llms-openai 0.1.31 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: llama-index-multi-modal-llms-openai 0.2.0 has requirement llama-index-core<0.12.0,>=0.11.0, but you'll have llama-index-core 0.10.68.post1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: llama-index-multi-modal-llms-openai 0.2.0 has requirement llama-index-llms-openai<0.3.0,>=0.2.0, but you'll have llama-index-llms-openai 0.1.31 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: llama-index-llms-huggingface 0.3.1 has requirement llama-index-core<0.12.0,>=0.11.0, but you'll have llama-index-core 0.10.68.post1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: llama-index-indices-managed-llama-cloud 0.3.0 has requirement llama-index-core<0.12.0,>=0.11.0, but you'll have llama-index-core 0.10.68.post1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: llama-index-embeddings-openai 0.2.3 has requirement llama-index-core<0.12.0,>=0.11.0, but you'll have llama-index-core 0.10.68.post1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: llama-index-cli 0.3.0 has requirement llama-index-core<0.12.0,>=0.11.0, but you'll have llama-index-core 0.10.68.post1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: llama-index-cli 0.3.0 has requirement llama-index-llms-openai<0.3.0,>=0.2.0, but you'll have llama-index-llms-openai 0.1.31 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: llama-index-agent-openai 0.3.0 has requirement llama-index-core<0.12.0,>=0.11.0, but you'll have llama-index-core 0.10.68.post1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: llama-index-agent-openai 0.3.0 has requirement llama-index-llms-openai<0.3.0,>=0.2.0, but you'll have llama-index-llms-openai 0.1.31 which is incompatible.\u001b[0m\n",
      "Installing collected packages: llama-index-core, llama-index-llms-openai\n",
      "  Attempting uninstall: llama-index-core\n",
      "    Found existing installation: llama-index-core 0.11.2\n",
      "    Uninstalling llama-index-core-0.11.2:\n",
      "      Successfully uninstalled llama-index-core-0.11.2\n",
      "  Attempting uninstall: llama-index-llms-openai\n",
      "    Found existing installation: llama-index-llms-openai 0.2.0\n",
      "    Uninstalling llama-index-llms-openai-0.2.0:\n",
      "      Successfully uninstalled llama-index-llms-openai-0.2.0\n",
      "Successfully installed llama-index-core-0.10.68.post1 llama-index-llms-openai-0.1.31\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: llama-index-readers-file in /usr/local/lib/python3.8/dist-packages (0.2.0)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /usr/local/lib/python3.8/dist-packages (from llama-index-readers-file) (0.0.26)\n",
      "Collecting llama-index-core<0.12.0,>=0.11.0\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/f0/7b/5db489b13598f375ca0745cdaf018d5292cec3f8e42e6520c08f15e2d614/llama_index_core-0.11.2-py3-none-any.whl (1.6 MB)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from llama-index-readers-file) (2.0.3)\n",
      "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in /usr/local/lib/python3.8/dist-packages (from llama-index-readers-file) (4.3.1)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.8/dist-packages (from llama-index-readers-file) (4.12.3)\n",
      "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (2.32.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (2024.6.1)\n",
      "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (3.9.1)\n",
      "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (2.0.32)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (6.0.1)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (1.0.8)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (2.8.2)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (1.5.8)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (3.10.5)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (1.16.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (3.1)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (1.2.14)\n",
      "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (1.24.4)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (0.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (4.12.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (0.7.0)\n",
      "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (0.6.7)\n",
      "Requirement already satisfied: httpx in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (0.27.2)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (10.4.0)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.8/dist-packages (from pandas->llama-index-readers-file) (2024.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.8/dist-packages (from pandas->llama-index-readers-file) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas->llama-index-readers-file) (2023.3.post1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.8/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file) (2.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (2.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (2.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (2019.11.28)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (1.4.2)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (8.1.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (2024.7.24)\n",
      "Requirement already satisfied: greenlet!=0.4.17; python_version < \"3.13\" and (platform_machine == \"aarch64\" or (platform_machine == \"ppc64le\" or (platform_machine == \"x86_64\" or (platform_machine == \"amd64\" or (platform_machine == \"AMD64\" or (platform_machine == \"win32\" or platform_machine == \"WIN32\")))))) in /usr/local/lib/python3.8/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (3.0.3)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.8/dist-packages (from pydantic<3.0.0,>=2.0.0->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (2.20.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from pydantic<3.0.0,>=2.0.0->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (0.7.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (2.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (23.1.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0; python_version < \"3.11\" in /usr/local/lib/python3.8/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (1.9.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (6.0.5)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.8/dist-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (3.22.0)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.8/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (1.0.5)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.8/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (1.3.0)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.8/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (4.0.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-readers-file) (1.14.0)\n",
      "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.8/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (23.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.8/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (0.14.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2; python_version < \"3.11\" in /usr/local/lib/python3.8/dist-packages (from anyio->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-file) (1.1.3)\n",
      "\u001b[31mERROR: llama-index 0.11.2 has requirement llama-index-llms-openai<0.3.0,>=0.2.0, but you'll have llama-index-llms-openai 0.1.31 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: llama-index-question-gen-openai 0.2.0 has requirement llama-index-llms-openai<0.3.0,>=0.2.0, but you'll have llama-index-llms-openai 0.1.31 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: llama-index-program-openai 0.2.0 has requirement llama-index-llms-openai<0.3.0,>=0.2.0, but you'll have llama-index-llms-openai 0.1.31 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: llama-index-postprocessor-cohere-rerank 0.1.7 has requirement llama-index-core<0.11.0,>=0.10.41, but you'll have llama-index-core 0.11.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: llama-index-multi-modal-llms-openai 0.2.0 has requirement llama-index-llms-openai<0.3.0,>=0.2.0, but you'll have llama-index-llms-openai 0.1.31 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: llama-index-llms-openai 0.1.31 has requirement llama-index-core<0.11.0,>=0.10.57, but you'll have llama-index-core 0.11.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: llama-index-llms-gradient 0.1.2 has requirement llama-index-core<0.11.0,>=0.10.1, but you'll have llama-index-core 0.11.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: llama-index-finetuning 0.1.7 has requirement llama-index-core<0.11.0,>=0.10.11.post1, but you'll have llama-index-core 0.11.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: llama-index-embeddings-adapter 0.1.3 has requirement llama-index-core<0.11.0,>=0.10.1, but you'll have llama-index-core 0.11.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: llama-index-cli 0.3.0 has requirement llama-index-llms-openai<0.3.0,>=0.2.0, but you'll have llama-index-llms-openai 0.1.31 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: llama-index-agent-openai 0.3.0 has requirement llama-index-llms-openai<0.3.0,>=0.2.0, but you'll have llama-index-llms-openai 0.1.31 which is incompatible.\u001b[0m\n",
      "Installing collected packages: llama-index-core\n",
      "  Attempting uninstall: llama-index-core\n",
      "    Found existing installation: llama-index-core 0.10.68.post1\n",
      "    Uninstalling llama-index-core-0.10.68.post1:\n",
      "      Successfully uninstalled llama-index-core-0.10.68.post1\n",
      "Successfully installed llama-index-core-0.11.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: llama_index in /usr/local/lib/python3.8/dist-packages (0.11.2)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.3.0,>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from llama_index) (0.2.0)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.3.0,>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from llama_index) (0.2.3)\n",
      "Requirement already satisfied: llama-index-program-openai<0.3.0,>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from llama_index) (0.2.0)\n",
      "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in /usr/local/lib/python3.8/dist-packages (from llama_index) (0.9.48.post3)\n",
      "Requirement already satisfied: llama-index-cli<0.4.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from llama_index) (0.3.0)\n",
      "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.2 in /usr/local/lib/python3.8/dist-packages (from llama_index) (0.11.2)\n",
      "Collecting llama-index-llms-openai<0.3.0,>=0.2.0\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/c2/81/036135a109ae1626246570fb57a1f6e874d8d33f2751763d642af98179f8/llama_index_llms_openai-0.2.0-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: llama-index-readers-file<0.3.0,>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from llama_index) (0.2.0)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from llama_index) (0.3.0)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from llama_index) (0.3.0)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.3.0,>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from llama_index) (0.2.0)\n",
      "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.8/dist-packages (from llama_index) (3.9.1)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from llama_index) (0.2.0)\n",
      "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from llama-index-embeddings-openai<0.3.0,>=0.2.0->llama_index) (1.42.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.8/dist-packages (from llama-index-legacy<0.10.0,>=0.9.48->llama_index) (0.7.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.8/dist-packages (from llama-index-legacy<0.10.0,>=0.9.48->llama_index) (4.12.2)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.8/dist-packages (from llama-index-legacy<0.10.0,>=0.9.48->llama_index) (1.2.14)\n",
      "Requirement already satisfied: httpx in /usr/local/lib/python3.8/dist-packages (from llama-index-legacy<0.10.0,>=0.9.48->llama_index) (0.27.2)\n",
      "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.8/dist-packages (from llama-index-legacy<0.10.0,>=0.9.48->llama_index) (3.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.8/dist-packages (from llama-index-legacy<0.10.0,>=0.9.48->llama_index) (2024.6.1)\n",
      "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.8/dist-packages (from llama-index-legacy<0.10.0,>=0.9.48->llama_index) (0.6.7)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.8/dist-packages (from llama-index-legacy<0.10.0,>=0.9.48->llama_index) (1.0.8)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from llama-index-legacy<0.10.0,>=0.9.48->llama_index) (0.9.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from llama-index-legacy<0.10.0,>=0.9.48->llama_index) (2.0.3)\n",
      "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.8/dist-packages (from llama-index-legacy<0.10.0,>=0.9.48->llama_index) (2.32.3)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.8/dist-packages (from llama-index-legacy<0.10.0,>=0.9.48->llama_index) (1.5.8)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from llama-index-legacy<0.10.0,>=0.9.48->llama_index) (1.24.4)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.8/dist-packages (from llama-index-legacy<0.10.0,>=0.9.48->llama_index) (8.5.0)\n",
      "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.8/dist-packages (from llama-index-legacy<0.10.0,>=0.9.48->llama_index) (2.0.32)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.8/dist-packages (from llama-index-legacy<0.10.0,>=0.9.48->llama_index) (3.10.5)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.2->llama_index) (6.0.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.2->llama_index) (2.8.2)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.2->llama_index) (10.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.2->llama_index) (4.66.5)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.2->llama_index) (1.16.0)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.8/dist-packages (from llama-index-readers-file<0.3.0,>=0.2.0->llama_index) (4.12.3)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /usr/local/lib/python3.8/dist-packages (from llama-index-readers-file<0.3.0,>=0.2.0->llama_index) (0.0.26)\n",
      "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in /usr/local/lib/python3.8/dist-packages (from llama-index-readers-file<0.3.0,>=0.2.0->llama_index) (4.3.1)\n",
      "Requirement already satisfied: llama-cloud>=0.0.11 in /usr/local/lib/python3.8/dist-packages (from llama-index-indices-managed-llama-cloud>=0.3.0->llama_index) (0.0.15)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk>3.8.1->llama_index) (2024.7.24)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk>3.8.1->llama_index) (8.1.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk>3.8.1->llama_index) (1.4.2)\n",
      "Requirement already satisfied: llama-parse>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from llama-index-readers-llama-parse>=0.2.0->llama_index) (0.5.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.8/dist-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.3.0,>=0.2.0->llama_index) (4.0.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.8/dist-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.3.0,>=0.2.0->llama_index) (1.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.8/dist-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.3.0,>=0.2.0->llama_index) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.3.0,>=0.2.0->llama_index) (0.5.0)\n",
      "Requirement already satisfied: idna in /usr/lib/python3/dist-packages (from httpx->llama-index-legacy<0.10.0,>=0.9.48->llama_index) (2.8)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.8/dist-packages (from httpx->llama-index-legacy<0.10.0,>=0.9.48->llama_index) (1.0.5)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from httpx->llama-index-legacy<0.10.0,>=0.9.48->llama_index) (2019.11.28)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.8/dist-packages (from dataclasses-json->llama-index-legacy<0.10.0,>=0.9.48->llama_index) (3.22.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from typing-inspect>=0.8.0->llama-index-legacy<0.10.0,>=0.9.48->llama_index) (1.0.0)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.8/dist-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama_index) (2024.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.8/dist-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama_index) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama_index) (2023.3.post1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.31.0->llama-index-legacy<0.10.0,>=0.9.48->llama_index) (2.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.31.0->llama-index-legacy<0.10.0,>=0.9.48->llama_index) (3.3.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17; python_version < \"3.13\" and (platform_machine == \"aarch64\" or (platform_machine == \"ppc64le\" or (platform_machine == \"x86_64\" or (platform_machine == \"amd64\" or (platform_machine == \"AMD64\" or (platform_machine == \"win32\" or platform_machine == \"WIN32\")))))) in /usr/local/lib/python3.8/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-legacy<0.10.0,>=0.9.48->llama_index) (3.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-legacy<0.10.0,>=0.9.48->llama_index) (23.1.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-legacy<0.10.0,>=0.9.48->llama_index) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0; python_version < \"3.11\" in /usr/local/lib/python3.8/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-legacy<0.10.0,>=0.9.48->llama_index) (4.0.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-legacy<0.10.0,>=0.9.48->llama_index) (6.0.5)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-legacy<0.10.0,>=0.9.48->llama_index) (2.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-legacy<0.10.0,>=0.9.48->llama_index) (1.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-legacy<0.10.0,>=0.9.48->llama_index) (1.9.4)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.8/dist-packages (from pydantic<3.0.0,>=2.0.0->llama-index-core<0.12.0,>=0.11.2->llama_index) (2.20.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from pydantic<3.0.0,>=2.0.0->llama-index-core<0.12.0,>=0.11.2->llama_index) (0.7.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.8/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.3.0,>=0.2.0->llama_index) (2.5)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2; python_version < \"3.11\" in /usr/local/lib/python3.8/dist-packages (from anyio<5,>=3.5.0->openai>=1.1.0->llama-index-embeddings-openai<0.3.0,>=0.2.0->llama_index) (1.1.3)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.8/dist-packages (from httpcore==1.*->httpx->llama-index-legacy<0.10.0,>=0.9.48->llama_index) (0.14.0)\n",
      "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.8/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-legacy<0.10.0,>=0.9.48->llama_index) (23.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-legacy<0.10.0,>=0.9.48->llama_index) (1.14.0)\n",
      "\u001b[31mERROR: llama-index-finetuning 0.1.7 has requirement llama-index-core<0.11.0,>=0.10.11.post1, but you'll have llama-index-core 0.11.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: llama-index-finetuning 0.1.7 has requirement llama-index-llms-openai<0.2.0,>=0.1.1, but you'll have llama-index-llms-openai 0.2.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: llama-index-llms-openai\n",
      "  Attempting uninstall: llama-index-llms-openai\n",
      "    Found existing installation: llama-index-llms-openai 0.1.31\n",
      "    Uninstalling llama-index-llms-openai-0.1.31:\n",
      "      Successfully uninstalled llama-index-llms-openai-0.1.31\n",
      "Successfully installed llama-index-llms-openai-0.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting llama_index.llms.huggingface\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/8b/fd/6347d8c93a463eb4be162ca08d4dccebfcca7800f24101d14b601b441a91/llama_index_llms_huggingface-0.3.1-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from llama_index.llms.huggingface) (0.11.2)\n",
      "Requirement already satisfied: text-generation<0.8.0,>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from llama_index.llms.huggingface) (0.7.0)\n",
      "Requirement already satisfied: torch<3.0.0,>=2.1.2 in /usr/local/lib/python3.8/dist-packages (from llama_index.llms.huggingface) (2.4.0)\n",
      "Requirement already satisfied: transformers[torch]<5.0.0,>=4.37.0 in /usr/local/lib/python3.8/dist-packages (from llama_index.llms.huggingface) (4.38.2)\n",
      "Requirement already satisfied: huggingface-hub<0.24.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from llama_index.llms.huggingface) (0.23.5)\n",
      "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama_index.llms.huggingface) (2.0.32)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama_index.llms.huggingface) (0.7.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama_index.llms.huggingface) (2024.6.1)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama_index.llms.huggingface) (0.9.0)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama_index.llms.huggingface) (3.10.5)\n",
      "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama_index.llms.huggingface) (1.24.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama_index.llms.huggingface) (4.66.5)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama_index.llms.huggingface) (2.8.2)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama_index.llms.huggingface) (6.0.1)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama_index.llms.huggingface) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama_index.llms.huggingface) (4.12.2)\n",
      "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama_index.llms.huggingface) (0.6.7)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama_index.llms.huggingface) (1.5.8)\n",
      "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama_index.llms.huggingface) (2.32.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama_index.llms.huggingface) (10.4.0)\n",
      "Requirement already satisfied: httpx in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama_index.llms.huggingface) (0.27.2)\n",
      "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama_index.llms.huggingface) (3.1)\n",
      "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama_index.llms.huggingface) (3.9.1)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama_index.llms.huggingface) (1.2.14)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama_index.llms.huggingface) (8.5.0)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama_index.llms.huggingface) (1.0.8)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch<3.0.0,>=2.1.2->llama_index.llms.huggingface) (2.20.5)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch<3.0.0,>=2.1.2->llama_index.llms.huggingface) (12.1.0.106)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from torch<3.0.0,>=2.1.2->llama_index.llms.huggingface) (3.1.2)\n",
      "Requirement already satisfied: triton==3.0.0; platform_system == \"Linux\" and platform_machine == \"x86_64\" and python_version < \"3.13\" in /usr/local/lib/python3.8/dist-packages (from torch<3.0.0,>=2.1.2->llama_index.llms.huggingface) (3.0.0)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch<3.0.0,>=2.1.2->llama_index.llms.huggingface) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch<3.0.0,>=2.1.2->llama_index.llms.huggingface) (11.4.5.107)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from torch<3.0.0,>=2.1.2->llama_index.llms.huggingface) (3.15.4)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.8/dist-packages (from torch<3.0.0,>=2.1.2->llama_index.llms.huggingface) (1.13.2)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch<3.0.0,>=2.1.2->llama_index.llms.huggingface) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch<3.0.0,>=2.1.2->llama_index.llms.huggingface) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch<3.0.0,>=2.1.2->llama_index.llms.huggingface) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch<3.0.0,>=2.1.2->llama_index.llms.huggingface) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch<3.0.0,>=2.1.2->llama_index.llms.huggingface) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch<3.0.0,>=2.1.2->llama_index.llms.huggingface) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch<3.0.0,>=2.1.2->llama_index.llms.huggingface) (12.1.105)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers[torch]<5.0.0,>=4.37.0->llama_index.llms.huggingface) (23.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers[torch]<5.0.0,>=4.37.0->llama_index.llms.huggingface) (2024.7.24)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.8/dist-packages (from transformers[torch]<5.0.0,>=4.37.0->llama_index.llms.huggingface) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from transformers[torch]<5.0.0,>=4.37.0->llama_index.llms.huggingface) (0.4.4)\n",
      "Requirement already satisfied: accelerate>=0.21.0; extra == \"torch\" in /usr/local/lib/python3.8/dist-packages (from transformers[torch]<5.0.0,>=4.37.0->llama_index.llms.huggingface) (0.33.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17; python_version < \"3.13\" and (platform_machine == \"aarch64\" or (platform_machine == \"ppc64le\" or (platform_machine == \"x86_64\" or (platform_machine == \"amd64\" or (platform_machine == \"AMD64\" or (platform_machine == \"win32\" or platform_machine == \"WIN32\")))))) in /usr/local/lib/python3.8/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama_index.llms.huggingface) (3.0.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.0->llama_index.llms.huggingface) (1.0.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama_index.llms.huggingface) (2.4.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama_index.llms.huggingface) (1.9.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama_index.llms.huggingface) (6.0.5)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0; python_version < \"3.11\" in /usr/local/lib/python3.8/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama_index.llms.huggingface) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama_index.llms.huggingface) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama_index.llms.huggingface) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama_index.llms.huggingface) (1.3.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from pydantic<3.0.0,>=2.0.0->llama-index-core<0.12.0,>=0.11.0->llama_index.llms.huggingface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.8/dist-packages (from pydantic<3.0.0,>=2.0.0->llama-index-core<0.12.0,>=0.11.0->llama_index.llms.huggingface) (2.20.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.8/dist-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama_index.llms.huggingface) (3.22.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama_index.llms.huggingface) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama_index.llms.huggingface) (2019.11.28)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama_index.llms.huggingface) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama_index.llms.huggingface) (2.8)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.8/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama_index.llms.huggingface) (1.3.0)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.8/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama_index.llms.huggingface) (4.0.0)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.8/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama_index.llms.huggingface) (1.0.5)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama_index.llms.huggingface) (1.4.2)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama_index.llms.huggingface) (8.1.7)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.8/dist-packages (from nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch<3.0.0,>=2.1.2->llama_index.llms.huggingface) (12.6.20)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->torch<3.0.0,>=2.1.2->llama_index.llms.huggingface) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from sympy->torch<3.0.0,>=2.1.2->llama_index.llms.huggingface) (1.3.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from accelerate>=0.21.0; extra == \"torch\"->transformers[torch]<5.0.0,>=4.37.0->llama_index.llms.huggingface) (5.9.6)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2; python_version < \"3.11\" in /usr/local/lib/python3.8/dist-packages (from anyio->httpx->llama-index-core<0.12.0,>=0.11.0->llama_index.llms.huggingface) (1.1.3)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.8/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.0->llama_index.llms.huggingface) (0.14.0)\n",
      "Installing collected packages: llama-index.llms.huggingface\n",
      "Successfully installed llama-index.llms.huggingface\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.8/dist-packages (0.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: einops in /usr/local/lib/python3.8/dist-packages (0.8.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: modelscope in /usr/local/lib/python3.8/dist-packages (1.17.1)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.8/dist-packages (from modelscope) (4.66.5)\n",
      "Requirement already satisfied: urllib3>=1.26 in /usr/local/lib/python3.8/dist-packages (from modelscope) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.25 in /usr/local/lib/python3.8/dist-packages (from modelscope) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.25->modelscope) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.25->modelscope) (2019.11.28)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.25->modelscope) (2.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting llama-index-embeddings-huggingface\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/05/14/7888378e644bce57f8475eeb186a9fb88c38abae962dd20c3c536b9c5cc4/llama_index_embeddings_huggingface-0.3.1-py3-none-any.whl (8.6 kB)\n",
      "Requirement already satisfied: huggingface-hub[inference]>=0.19.0 in /usr/local/lib/python3.8/dist-packages (from llama-index-embeddings-huggingface) (0.23.5)\n",
      "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from llama-index-embeddings-huggingface) (0.11.2)\n",
      "Requirement already satisfied: sentence-transformers>=2.6.1 in /usr/local/lib/python3.8/dist-packages (from llama-index-embeddings-huggingface) (2.7.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.0.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.12.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.32.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.15.4)\n",
      "Requirement already satisfied: aiohttp; extra == \"inference\" in /usr/local/lib/python3.8/dist-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.10.5)\n",
      "Collecting minijinja>=1.0; extra == \"inference\"\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/80/f0/87dbc02dc870d0bf50a064edf41fb255014d248bf118a3ee6b5721fc33dc/minijinja-2.2.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (861 kB)\n",
      "\u001b[K     || 861 kB 6.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (3.1)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.2.14)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (0.7.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (2.8.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (8.5.0)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.0.8)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (10.4.0)\n",
      "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (0.6.7)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.16.0)\n",
      "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.24.4)\n",
      "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (2.0.32)\n",
      "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (3.9.1)\n",
      "Requirement already satisfied: httpx in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (0.27.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (0.9.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.8/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.5.8)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (2.4.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.8/dist-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (4.38.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2019.11.28)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.2.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp; extra == \"inference\"->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp; extra == \"inference\"->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp; extra == \"inference\"->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp; extra == \"inference\"->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.4.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0; python_version < \"3.11\" in /usr/local/lib/python3.8/dist-packages (from aiohttp; extra == \"inference\"->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp; extra == \"inference\"->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.9.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp; extra == \"inference\"->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.0.5)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.8/dist-packages (from tiktoken>=0.3.3->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (2024.7.24)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.8/dist-packages (from pydantic<3.0.0,>=2.0.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (2.20.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from pydantic<3.0.0,>=2.0.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (0.7.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.8/dist-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (3.22.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17; python_version < \"3.13\" and (platform_machine == \"aarch64\" or (platform_machine == \"ppc64le\" or (platform_machine == \"x86_64\" or (platform_machine == \"amd64\" or (platform_machine == \"AMD64\" or (platform_machine == \"win32\" or platform_machine == \"WIN32\")))))) in /usr/local/lib/python3.8/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (3.0.3)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.4.2)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (8.1.7)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.8/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.0.5)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.8/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (4.0.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.8/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.3.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.0.0)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (2.20.5)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (11.4.5.107)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.1.2)\n",
      "Requirement already satisfied: triton==3.0.0; platform_system == \"Linux\" and platform_machine == \"x86_64\" and python_version < \"3.13\" in /usr/local/lib/python3.8/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.0.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.8/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.13.2)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (10.3.2.106)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.4.4)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.8/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.15.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.5.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.8/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (0.14.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2; python_version < \"3.11\" in /usr/local/lib/python3.8/dist-packages (from anyio->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.1.3)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.8/dist-packages (from nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (12.6.20)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from sympy->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.3.0)\n",
      "Installing collected packages: llama-index-embeddings-huggingface, minijinja\n",
      "Successfully installed llama-index-embeddings-huggingface-0.3.1 minijinja-2.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install llama-index-llms-openai\n",
    "%pip install llama-index-embeddings-openai\n",
    "%pip install llama-index-finetuning\n",
    "%pip install llama-index-readers-file\n",
    "%pip install llama_index\n",
    "%pip install llama_index.llms.huggingface\n",
    "%pip install sentencepiece\n",
    "%pip install einops\n",
    "%pip install modelscope\n",
    "%pip install llama-index-embeddings-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b16e886b-efbb-4c34-9788-cd02a0f10f34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.schema import MetadataMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06a66d60-a88f-4c3f-b139-bcef1b1c21ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAIN_FILES = [\"./data/train.txt\"]\n",
    "VAL_FILES = [\"./data/val.txt\"]\n",
    "\n",
    "# TRAIN_CORPUS_FPATH = \"./data/train_corpus.json\"\n",
    "# VAL_CORPUS_FPATH = \"./data/val_corpus.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9b6d14a-3185-4951-b14b-db081e35e34b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_corpus(files, verbose=False):\n",
    "    if verbose:\n",
    "        print(f\"Loading files {files}\")\n",
    "\n",
    "    reader = SimpleDirectoryReader(input_files=files)\n",
    "    docs = reader.load_data()\n",
    "    if verbose:\n",
    "        print(f\"Loaded {len(docs)} docs\")\n",
    "\n",
    "    parser = SentenceSplitter()\n",
    "    nodes = parser.get_nodes_from_documents(docs, show_progress=verbose)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Parsed {len(nodes)} nodes\")\n",
    "\n",
    "    return nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61e49a3b-525e-4bd6-b247-6986619866cf",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files ['./data/train.txt']\n",
      "Loaded 1 docs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Parsing nodes: 100%|| 1/1 [00:00<00:00, 243.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed 5 nodes\n",
      "Loading files ['./data/val.txt']\n",
      "Loaded 1 docs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing nodes: 100%|| 1/1 [00:00<00:00, 122.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed 8 nodes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_nodes = load_corpus(TRAIN_FILES, verbose=True)\n",
    "val_nodes = load_corpus(VAL_FILES, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48ba547c-bd9a-481f-9b20-eeb7dfefc5f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/pydantic/_internal/_fields.py:161: UserWarning: Field \"model_adapter_id\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from llama_index.finetuning import generate_qa_embedding_pairs\n",
    "from llama_index.core.evaluation import EmbeddingQAFinetuneDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "934a8b79-7d07-4138-810c-322f20ce0ca9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# OPENAI_BASE_URL=\"https://api.wlai.vip/v1\"\n",
    "# OPENAI_API_KEY = \"sk-\"\n",
    "# os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "# os.environ[\"OPENAI_BASE_URL\"] = OPENAI_BASE_URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd11093c-62c8-44e2-a80f-109fdd8bf6c0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/344 [04:17<24:30:35, 257.25s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[0;32m----> 4\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_qa_embedding_pairs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-3.5-turbo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mOPENAI_API_KEY\u001b[49m\u001b[43m,\u001b[49m\u001b[43mapi_base\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mOPENAI_BASE_URL\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_nodes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m generate_qa_embedding_pairs(llm\u001b[38;5;241m=\u001b[39mOpenAI(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-3.5-turbo\u001b[39m\u001b[38;5;124m\"\u001b[39m,api_key\u001b[38;5;241m=\u001b[39mOPENAI_API_KEY,api_base\u001b[38;5;241m=\u001b[39mOPENAI_BASE_URL), nodes\u001b[38;5;241m=\u001b[39mval_nodes)\n\u001b[1;32m      7\u001b[0m train_dataset\u001b[38;5;241m.\u001b[39msave_json(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_dataset.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/llama_index/finetuning/embeddings/common.py:87\u001b[0m, in \u001b[0;36mgenerate_qa_embedding_pairs\u001b[0;34m(nodes, llm, qa_generate_prompt_tmpl, num_questions_per_chunk)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node_id, text \u001b[38;5;129;01min\u001b[39;00m tqdm(node_dict\u001b[38;5;241m.\u001b[39mitems()):\n\u001b[1;32m     84\u001b[0m     query \u001b[38;5;241m=\u001b[39m qa_generate_prompt_tmpl\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     85\u001b[0m         context_str\u001b[38;5;241m=\u001b[39mtext, num_questions_per_chunk\u001b[38;5;241m=\u001b[39mnum_questions_per_chunk\n\u001b[1;32m     86\u001b[0m     )\n\u001b[0;32m---> 87\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomplete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(response)\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     90\u001b[0m     questions \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     91\u001b[0m         re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m^\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+[\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms]\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, question)\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m question \u001b[38;5;129;01min\u001b[39;00m result\n\u001b[1;32m     92\u001b[0m     ]\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/llama_index/core/instrumentation/dispatcher.py:261\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[1;32m    254\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_,\n\u001b[1;32m    255\u001b[0m     bound_args\u001b[38;5;241m=\u001b[39mbound_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    258\u001b[0m     tags\u001b[38;5;241m=\u001b[39mtags,\n\u001b[1;32m    259\u001b[0m )\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 261\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/llama_index/core/llms/callbacks.py:434\u001b[0m, in \u001b[0;36mllm_completion_callback.<locals>.wrap.<locals>.wrapped_llm_predict\u001b[0;34m(_self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    425\u001b[0m event_id \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_event_start(\n\u001b[1;32m    426\u001b[0m     CBEventType\u001b[38;5;241m.\u001b[39mLLM,\n\u001b[1;32m    427\u001b[0m     payload\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    431\u001b[0m     },\n\u001b[1;32m    432\u001b[0m )\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 434\u001b[0m     f_return_val \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    436\u001b[0m     callback_manager\u001b[38;5;241m.\u001b[39mon_event_end(\n\u001b[1;32m    437\u001b[0m         CBEventType\u001b[38;5;241m.\u001b[39mLLM,\n\u001b[1;32m    438\u001b[0m         payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mEXCEPTION: e},\n\u001b[1;32m    439\u001b[0m         event_id\u001b[38;5;241m=\u001b[39mevent_id,\n\u001b[1;32m    440\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/llama_index/llms/openai/base.py:354\u001b[0m, in \u001b[0;36mOpenAI.complete\u001b[0;34m(self, prompt, formatted, **kwargs)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    353\u001b[0m     complete_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_complete\n\u001b[0;32m--> 354\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcomplete_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/llama_index/core/base/llms/generic_utils.py:173\u001b[0m, in \u001b[0;36mchat_to_completion_decorator.<locals>.wrapper\u001b[0;34m(prompt, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(prompt: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m CompletionResponse:\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;66;03m# normalize input\u001b[39;00m\n\u001b[1;32m    172\u001b[0m     messages \u001b[38;5;241m=\u001b[39m prompt_to_messages(prompt)\n\u001b[0;32m--> 173\u001b[0m     chat_response \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;66;03m# normalize output\u001b[39;00m\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m chat_response_to_completion_response(chat_response)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/llama_index/llms/openai/base.py:95\u001b[0m, in \u001b[0;36mllm_retry_decorator.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     88\u001b[0m retry \u001b[38;5;241m=\u001b[39m create_retry_decorator(\n\u001b[1;32m     89\u001b[0m     max_retries\u001b[38;5;241m=\u001b[39mmax_retries,\n\u001b[1;32m     90\u001b[0m     random_exponential\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     93\u001b[0m     max_seconds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[1;32m     94\u001b[0m )\n\u001b[0;32m---> 95\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tenacity/__init__.py:336\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    334\u001b[0m copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    335\u001b[0m wrapped_f\u001b[38;5;241m.\u001b[39mstatistics \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mstatistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m--> 336\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tenacity/__init__.py:475\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 475\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    476\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    477\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tenacity/__init__.py:376\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    374\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[0;32m--> 376\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tenacity/__init__.py:398\u001b[0m, in \u001b[0;36mBaseRetrying._post_retry_check_actions.<locals>.<lambda>\u001b[0;34m(rs)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_post_retry_check_actions\u001b[39m(\u001b[38;5;28mself\u001b[39m, retry_state: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetryCallState\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mis_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mretry_run_result):\n\u001b[0;32m--> 398\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_action_func(\u001b[38;5;28;01mlambda\u001b[39;00m rs: \u001b[43mrs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutcome\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    399\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.8/concurrent/futures/_base.py:437\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    435\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/usr/lib/python3.8/concurrent/futures/_base.py:389\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 389\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    391\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    392\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tenacity/__init__.py:478\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 478\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[1;32m    480\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/llama_index/llms/openai/base.py:408\u001b[0m, in \u001b[0;36mOpenAI._chat\u001b[0;34m(self, messages, **kwargs)\u001b[0m\n\u001b[1;32m    405\u001b[0m message_dicts \u001b[38;5;241m=\u001b[39m to_openai_message_dicts(messages)\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreuse_client:\n\u001b[0;32m--> 408\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_model_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    414\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m client:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/openai/_utils/_utils.py:274\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/openai/resources/chat/completions.py:668\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    635\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    665\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    666\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    667\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m--> 668\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/openai/_base_client.py:1260\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1246\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1247\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1248\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1255\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1256\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1257\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1258\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1259\u001b[0m     )\n\u001b[0;32m-> 1260\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/openai/_base_client.py:937\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    929\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    930\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    935\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    936\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 937\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/openai/_base_client.py:973\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    970\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSending HTTP Request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, request\u001b[38;5;241m.\u001b[39mmethod, request\u001b[38;5;241m.\u001b[39murl)\n\u001b[1;32m    972\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 973\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    979\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/httpx/_client.py:926\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[1;32m    924\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 926\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/httpx/_client.py:954\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    951\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 954\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    959\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    960\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/httpx/_client.py:991\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    989\u001b[0m     hook(request)\n\u001b[0;32m--> 991\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    993\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/httpx/_client.py:1027\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1023\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1024\u001b[0m     )\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1027\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1031\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/httpx/_transports/default.py:236\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    223\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    224\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    225\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    233\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    234\u001b[0m )\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 236\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    241\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    242\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    243\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    244\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    245\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/httpcore/_sync/connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    213\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, Iterable)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/httpcore/_sync/connection_pool.py:196\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    192\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/httpcore/_sync/http_proxy.py:344\u001b[0m, in \u001b[0;36mTunnelHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection \u001b[38;5;241m=\u001b[39m HTTP11Connection(\n\u001b[1;32m    338\u001b[0m                 origin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_remote_origin,\n\u001b[1;32m    339\u001b[0m                 stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m    340\u001b[0m                 keepalive_expiry\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_keepalive_expiry,\n\u001b[1;32m    341\u001b[0m             )\n\u001b[1;32m    343\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connected \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 344\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/httpcore/_sync/http11.py:143\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/httpcore/_sync/http11.py:113\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m    106\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    107\u001b[0m     (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m         trailing_data,\n\u001b[0;32m--> 113\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    115\u001b[0m         http_version,\n\u001b[1;32m    116\u001b[0m         status,\n\u001b[1;32m    117\u001b[0m         reason_phrase,\n\u001b[1;32m    118\u001b[0m         headers,\n\u001b[1;32m    119\u001b[0m     )\n\u001b[1;32m    121\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/httpcore/_sync/http11.py:186\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    183\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 186\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/httpcore/_sync/http11.py:224\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    221\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 224\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/httpcore/_backends/sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.8/ssl.py:1226\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1223\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1224\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1225\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1226\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1228\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m/usr/lib/python3.8/ssl.py:1101\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1099\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1101\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1102\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[1;32m   1103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# from llama_index.llms.openai import OpenAI\n",
    "\n",
    "\n",
    "# train_dataset = generate_qa_embedding_pairs(llm=OpenAI(model=\"gpt-3.5-turbo\",api_key=OPENAI_API_KEY,api_base=OPENAI_BASE_URL), nodes=train_nodes)\n",
    "# val_dataset = generate_qa_embedding_pairs(llm=OpenAI(model=\"gpt-3.5-turbo\",api_key=OPENAI_API_KEY,api_base=OPENAI_BASE_URL), nodes=val_nodes)\n",
    "\n",
    "# train_dataset.save_json(\"train_dataset.json\")\n",
    "# val_dataset.save_json(\"val_dataset.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3cb918-72ab-4783-8379-89e54a599f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/pydantic/_internal/_fields.py:161: UserWarning: Field \"model_id\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/pydantic/_internal/_fields.py:161: UserWarning: Field \"model_name\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/pydantic/_internal/_fields.py:161: UserWarning: Field \"model_kwargs\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "The repository for /share/new_models/Shanghai_AI_Laboratory/internlm2-chat-1_8b contains custom code which must be executed to correctly load the model. You can inspect the repository content at https://hf.co//share/new_models/Shanghai_AI_Laboratory/internlm2-chat-1_8b.\n",
      "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
      "\n",
      "Do you wish to run the custom code? [y/N]  y\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "\n",
    "# \n",
    "model_name_or_path = \"/share/new_models/Shanghai_AI_Laboratory/internlm2-chat-1_8b\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_name_or_path)\n",
    "llm = HuggingFaceLLM(model_name=model_name_or_path, tokenizer_name=model_name_or_path)\n",
    "\n",
    "train_dataset = generate_qa_embedding_pairs(llm=llm, nodes=train_nodes)\n",
    "val_dataset = generate_qa_embedding_pairs(llm=llm, nodes=val_nodes)\n",
    "\n",
    "train_dataset.save_json(\"./data/train_dataset.json\")\n",
    "val_dataset.save_json(\"./data/val_dataset.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c14188e8-3607-4610-a8d8-42bac80520e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Optional] Load\n",
    "train_dataset = EmbeddingQAFinetuneDataset.from_json(\"./data/train_dataset.json\")\n",
    "val_dataset = EmbeddingQAFinetuneDataset.from_json(\"./data/train_dataset.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3abcfbf-4398-4ae2-b7dd-d54d958b5011",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.finetuning import SentenceTransformersFinetuneEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57c5f99e-aa2d-45a1-bd50-3c9624e1e4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-08-29 22:46:53,823 - modelscope - WARNING - Using branch: master as version is unstable, use with caution\n"
     ]
    }
   ],
   "source": [
    "from modelscope import snapshot_download\n",
    "#  master\n",
    "model_dir = snapshot_download('AI-ModelScope/bge-small-zh-v1.5', cache_dir='/root', revision='master')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5085d451-ad09-4f66-835b-0f172b9882a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_engine = SentenceTransformersFinetuneEngine(\n",
    "    train_dataset,\n",
    "    model_id=\"/root/AI-ModelScope/bge-small-zh-v1___5\",\n",
    "    model_output_path=\"test_model\",\n",
    "    val_dataset=val_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c1dd421-5f27-450a-aae6-23e3def469c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8d5753a0b9d47a895921450f671cf3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4fcfa3237b7494390def678c7e9508e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7be82e2c808e4dcf9a62a79e7ece084d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "finetune_engine.finetune()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab6e90d7-93e6-47a6-9e42-d9460c60c761",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model = finetune_engine.get_finetuned_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65f1f00a-9004-4375-8b4c-f3b17031120b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbedding(model_name='test_model', embed_batch_size=10, callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x7f4ff097b5b0>, num_workers=None, max_length=512, normalize=True, query_instruction=None, text_instruction=None, cache_folder=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea208b1d-c297-432a-bf63-121aaa696aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.schema import TextNode\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9b76b71-fc59-4009-b53f-ccfa17029364",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(\n",
    "    dataset,\n",
    "    embed_model,\n",
    "    top_k=5,\n",
    "    verbose=False,\n",
    "):\n",
    "    corpus = dataset.corpus\n",
    "    queries = dataset.queries\n",
    "    relevant_docs = dataset.relevant_docs\n",
    "\n",
    "    nodes = [TextNode(id_=id_, text=text) for id_, text in corpus.items()]\n",
    "    index = VectorStoreIndex(\n",
    "        nodes, embed_model=embed_model, show_progress=True\n",
    "    )\n",
    "    retriever = index.as_retriever(similarity_top_k=top_k)\n",
    "\n",
    "    eval_results = []\n",
    "    for query_id, query in tqdm(queries.items()):\n",
    "        retrieved_nodes = retriever.retrieve(query)\n",
    "        retrieved_ids = [node.node.node_id for node in retrieved_nodes]\n",
    "        expected_id = relevant_docs[query_id][0]\n",
    "        is_hit = expected_id in retrieved_ids  # assume 1 relevant doc\n",
    "\n",
    "        eval_result = {\n",
    "            \"is_hit\": is_hit,\n",
    "            \"retrieved\": retrieved_ids,\n",
    "            \"expected\": expected_id,\n",
    "            \"query\": query_id,\n",
    "        }\n",
    "        eval_results.append(eval_result)\n",
    "    return eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "644c7497-e603-4027-bc9f-dab9d532e35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.evaluation import InformationRetrievalEvaluator\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def evaluate_st(\n",
    "    dataset,\n",
    "    model_id,\n",
    "    name,\n",
    "):\n",
    "    corpus = dataset.corpus\n",
    "    queries = dataset.queries\n",
    "    relevant_docs = dataset.relevant_docs\n",
    "\n",
    "    evaluator = InformationRetrievalEvaluator(\n",
    "        queries, corpus, relevant_docs, name=name\n",
    "    )\n",
    "    model = SentenceTransformer(model_id)\n",
    "    output_path = \"results/\"\n",
    "    Path(output_path).mkdir(exist_ok=True, parents=True)\n",
    "    return evaluator(model, output_path=output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04a7a8ab-5e77-4717-ba61-6bca2d877c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.8/dist-packages (8.1.5)\n",
      "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.8/dist-packages (from ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets) (8.12.3)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.8/dist-packages (from ipywidgets) (5.13.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in /usr/local/lib/python3.8/dist-packages (from ipywidgets) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /usr/local/lib/python3.8/dist-packages (from ipywidgets) (3.0.13)\n",
      "Requirement already satisfied: pexpect>4.3; sys_platform != \"win32\" in /usr/local/lib/python3.8/dist-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.8/dist-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: typing-extensions; python_version < \"3.10\" in /usr/local/lib/python3.8/dist-packages (from ipython>=6.1.0->ipywidgets) (4.12.2)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /usr/local/lib/python3.8/dist-packages (from ipython>=6.1.0->ipywidgets) (3.0.41)\n",
      "Requirement already satisfied: stack-data in /usr/local/lib/python3.8/dist-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.8/dist-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.8/dist-packages (from ipython>=6.1.0->ipywidgets) (2.16.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect>4.3; sys_platform != \"win32\"->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.10)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /usr/local/lib/python3.8/dist-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /usr/local/lib/python3.8/dist-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: executing>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf30329c-b22a-44f8-bda3-795174fa6046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9d19e783e29428ab1ccc89ba6c395ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "153719a68ac44e8c8c0639fdbf849dc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bge = \"local:/root/AI-ModelScope/bge-small-zh-v1___5\"\n",
    "bge_val_results = evaluate(val_dataset, bge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e879b53-39f3-4499-95f5-f5633a560184",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bge = pd.DataFrame(bge_val_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4eb2d6df-ce6c-4089-8661-3b25fc6e0185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_hit</th>\n",
       "      <th>retrieved</th>\n",
       "      <th>expected</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>[990770fc-825d-455e-bcc5-bc859a4a355a, 2672652...</td>\n",
       "      <td>3f2beccc-723d-44a2-bb0d-e59c493b569d</td>\n",
       "      <td>65475173-f069-431e-9cfa-f4e0d0f034c8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>[2672652e-58ff-4280-9941-24f6cd00721a, 3f2becc...</td>\n",
       "      <td>3f2beccc-723d-44a2-bb0d-e59c493b569d</td>\n",
       "      <td>18c1aae5-e5a4-466c-9dea-cfa6ae9c4cb4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>[8d7405e8-ce84-4ea5-88e4-8a71cfda31e2, 990770f...</td>\n",
       "      <td>8d7405e8-ce84-4ea5-88e4-8a71cfda31e2</td>\n",
       "      <td>badad0ec-2045-4724-bc96-468154275042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>[2672652e-58ff-4280-9941-24f6cd00721a, 3f2becc...</td>\n",
       "      <td>8d7405e8-ce84-4ea5-88e4-8a71cfda31e2</td>\n",
       "      <td>c34f9bbf-7254-4984-bdf6-8d24e63a7c86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>[3f2beccc-723d-44a2-bb0d-e59c493b569d, 2672652...</td>\n",
       "      <td>80402cdd-a01d-414a-a9d8-db80b3be63f9</td>\n",
       "      <td>e1d911ea-bddf-4f4d-89bc-33fa9fd4fc55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>True</td>\n",
       "      <td>[2672652e-58ff-4280-9941-24f6cd00721a, 3f2becc...</td>\n",
       "      <td>80402cdd-a01d-414a-a9d8-db80b3be63f9</td>\n",
       "      <td>70ef2734-c540-43d0-9740-1989089006ca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>True</td>\n",
       "      <td>[8d7405e8-ce84-4ea5-88e4-8a71cfda31e2, 990770f...</td>\n",
       "      <td>2672652e-58ff-4280-9941-24f6cd00721a</td>\n",
       "      <td>fd9e3749-ea9f-43c7-a67e-5f1b049a2c41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>True</td>\n",
       "      <td>[2672652e-58ff-4280-9941-24f6cd00721a, 8d7405e...</td>\n",
       "      <td>2672652e-58ff-4280-9941-24f6cd00721a</td>\n",
       "      <td>2d4dff8c-f880-40f5-96a3-d8d3c470b068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>True</td>\n",
       "      <td>[2672652e-58ff-4280-9941-24f6cd00721a, 3f2becc...</td>\n",
       "      <td>990770fc-825d-455e-bcc5-bc859a4a355a</td>\n",
       "      <td>04099bd3-716b-4ce6-9d05-330406981c1c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>True</td>\n",
       "      <td>[3f2beccc-723d-44a2-bb0d-e59c493b569d, 2672652...</td>\n",
       "      <td>990770fc-825d-455e-bcc5-bc859a4a355a</td>\n",
       "      <td>5caceebb-ca9e-49d4-8cbf-00413a0d61c6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_hit                                          retrieved  \\\n",
       "0    True  [990770fc-825d-455e-bcc5-bc859a4a355a, 2672652...   \n",
       "1    True  [2672652e-58ff-4280-9941-24f6cd00721a, 3f2becc...   \n",
       "2    True  [8d7405e8-ce84-4ea5-88e4-8a71cfda31e2, 990770f...   \n",
       "3    True  [2672652e-58ff-4280-9941-24f6cd00721a, 3f2becc...   \n",
       "4    True  [3f2beccc-723d-44a2-bb0d-e59c493b569d, 2672652...   \n",
       "5    True  [2672652e-58ff-4280-9941-24f6cd00721a, 3f2becc...   \n",
       "6    True  [8d7405e8-ce84-4ea5-88e4-8a71cfda31e2, 990770f...   \n",
       "7    True  [2672652e-58ff-4280-9941-24f6cd00721a, 8d7405e...   \n",
       "8    True  [2672652e-58ff-4280-9941-24f6cd00721a, 3f2becc...   \n",
       "9    True  [3f2beccc-723d-44a2-bb0d-e59c493b569d, 2672652...   \n",
       "\n",
       "                               expected                                 query  \n",
       "0  3f2beccc-723d-44a2-bb0d-e59c493b569d  65475173-f069-431e-9cfa-f4e0d0f034c8  \n",
       "1  3f2beccc-723d-44a2-bb0d-e59c493b569d  18c1aae5-e5a4-466c-9dea-cfa6ae9c4cb4  \n",
       "2  8d7405e8-ce84-4ea5-88e4-8a71cfda31e2  badad0ec-2045-4724-bc96-468154275042  \n",
       "3  8d7405e8-ce84-4ea5-88e4-8a71cfda31e2  c34f9bbf-7254-4984-bdf6-8d24e63a7c86  \n",
       "4  80402cdd-a01d-414a-a9d8-db80b3be63f9  e1d911ea-bddf-4f4d-89bc-33fa9fd4fc55  \n",
       "5  80402cdd-a01d-414a-a9d8-db80b3be63f9  70ef2734-c540-43d0-9740-1989089006ca  \n",
       "6  2672652e-58ff-4280-9941-24f6cd00721a  fd9e3749-ea9f-43c7-a67e-5f1b049a2c41  \n",
       "7  2672652e-58ff-4280-9941-24f6cd00721a  2d4dff8c-f880-40f5-96a3-d8d3c470b068  \n",
       "8  990770fc-825d-455e-bcc5-bc859a4a355a  04099bd3-716b-4ce6-9d05-330406981c1c  \n",
       "9  990770fc-825d-455e-bcc5-bc859a4a355a  5caceebb-ca9e-49d4-8cbf-00413a0d61c6  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "055096f9-bd18-4d42-8634-c40247ddfab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hit_rate_bge = df_bge[\"is_hit\"].mean()\n",
    "hit_rate_bge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d04d08e-59ac-40b3-927d-979aae7ff157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43166666666666664"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_st(val_dataset, \"/root/AI-ModelScope/bge-small-zh-v1___5\", name=\"bge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b00fadce-57e5-44fb-b2db-acf0d19aeb7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92863a0a39644d6ba679797d8ff48275",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c860800c52645d79eedc25df213f518",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "finetuned = \"local:test_model\"\n",
    "val_results_finetuned = evaluate(val_dataset, finetuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e57568e7-86eb-4d16-b29d-81abeddde7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_finetuned = pd.DataFrame(val_results_finetuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a5ccb446-a3d6-4001-889f-22fb6272dd1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hit_rate_finetuned = df_finetuned[\"is_hit\"].mean()\n",
    "hit_rate_finetuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f058377-398c-427e-9b84-b958755ddb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_st(val_dataset, \"test_model\", name=\"finetuned\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
