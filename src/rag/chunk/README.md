# 分块方法
## 1. big to small chunk 


### 基本介绍

由大到小切块，换角度说就是由小到大检索

在索引阶段创建两种颗粒度的文本块，主要在于块大小的权衡:

*小块*：尺寸较小（如100-256字），用于向量检索，检索精度高，能更精准地定位到包含答案的文本。但上下文信息可能不足，大模型可能因为缺乏足够的背景信息而无法生成高质量答案。其目的是精准定位，像一把手术刀，确保召回的片段与查询高度相关。

*大块*：尺寸较大（如512-1024字），是小块所在的父级段落或章节。包含丰富的上下文信息，利于大模型生成，其目的是提供丰富上下文，确保大模型有足够的背景信息来生成连贯、准确的答案，但会引入很多噪声，降低检索精度，因为向量检索可能返回的是相关性不高的大块。

关键机制是建立从小块到其源大块的映射关系，它的精髓就在于：它巧妙地规避了这个权衡，做到了鱼和熊掌兼得。

### 工作流程

小检索：在索引阶段，将原始文档切分成两种颗粒度的片段，“小片段“用于检索尺寸较小（如100-256）的字符，旨在精准捕获关键信息。“大片段”用于生成尺寸较大（如512-1024）的字符，提供充足的上下文。关键一步：建立“小片段“到其父“大片段”的映射关系（例如，每个小片段都记录自己是从哪个大片段中切出来的）。在检索阶段，使用用户的查询去向量数据库中搜索最相关的 Top-K 个“小”片段。

大投喂：获取到Top-K个相关的小片段后，不是直接将这些小片段喂给大模型。而是根据之前建立的映射关系，找到这些小片段对应的父大片段。将这些大片段去重后作为上下文，与用户查询一起组合成提示（Prompt），发送给大模型以生成最终答案。

流程总结：查询 -> 用查询向量检索最相关的小块 -> 通过映射找到这些小块对应的大块 -> 将大块去重后作为上下文发送给大模型生成答案
